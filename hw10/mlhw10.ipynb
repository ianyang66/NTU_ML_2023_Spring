{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87ddb566",
   "metadata": {
    "id": "H9m2AbpHC9vS",
    "papermill": {
     "duration": 0.010738,
     "end_time": "2023-05-13T09:23:30.866090",
     "exception": false,
     "start_time": "2023-05-13T09:23:30.855352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Homework 10 - Adversarial Attack**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b14b4ac0",
   "metadata": {
    "id": "k0G8g5KuDBzU",
    "papermill": {
     "duration": 0.009769,
     "end_time": "2023-05-13T09:23:30.886148",
     "exception": false,
     "start_time": "2023-05-13T09:23:30.876379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Enviroment & Download\n",
    "\n",
    "We make use of [pytorchcv](https://pypi.org/project/pytorchcv/) to obtain CIFAR-10 pretrained model, so we need to set up the enviroment first. We also need to download the data (200 images) which we want to attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb296b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:23:30.908544Z",
     "iopub.status.busy": "2023-05-13T09:23:30.907450Z",
     "iopub.status.idle": "2023-05-13T09:24:11.228039Z",
     "shell.execute_reply": "2023-05-13T09:24:11.226868Z"
    },
    "id": "yMK1RhUQCz1e",
    "outputId": "00ccab9c-0b4d-4c9a-d3f1-8b6c542e61c6",
    "papermill": {
     "duration": 40.334365,
     "end_time": "2023-05-13T09:24:11.230498",
     "exception": false,
     "start_time": "2023-05-13T09:23:30.896133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorchcv\r\n",
      "  Downloading pytorchcv-0.0.67-py2.py3-none-any.whl (532 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.4/532.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (2.28.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorchcv) (1.23.5)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorchcv) (1.26.15)\r\n",
      "Installing collected packages: pytorchcv\r\n",
      "Successfully installed pytorchcv-0.0.67\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: imgaug in /opt/conda/lib/python3.10/site-packages (0.4.0)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from imgaug) (4.5.4.60)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from imgaug) (1.9.3)\r\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /opt/conda/lib/python3.10/site-packages (from imgaug) (0.20.0)\r\n",
      "Requirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from imgaug) (1.8.5.post1)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from imgaug) (9.5.0)\r\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.10/site-packages (from imgaug) (1.23.5)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from imgaug) (3.6.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from imgaug) (1.16.0)\r\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from imgaug) (2.27.0)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (3.1)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (0.2)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (2023.3.21)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (21.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (1.4.4)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (0.11.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (2.8.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (4.39.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug) (1.0.7)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m--2023-05-13 09:23:55--  https://www.dropbox.com/s/lbpypqamqjpt2qz/data.zip\r\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\r\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /s/raw/lbpypqamqjpt2qz/data.zip [following]\r\n",
      "--2023-05-13 09:23:55--  https://www.dropbox.com/s/raw/lbpypqamqjpt2qz/data.zip\r\n",
      "Reusing existing connection to www.dropbox.com:443.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://uc825fbd1cfbc6135e74d84d5fed.dl.dropboxusercontent.com/cd/0/inline/B7_Tfl2cTZ8M04pXotOHXCg0r-HD8p5OtMjw2dky5ia2wNVC6zY4ix6TmDFJxFwf5VSkDfSoIpTGzC9HRUqT4MO4x6WSz1_mJVyy4glmh5a3FMOnoa8aglRydQCpUisDCJW53skJ9LIxrVxeWOjkDMuPwvIOC5c-nMSXvR055Hk09A/file# [following]\r\n",
      "--2023-05-13 09:23:56--  https://uc825fbd1cfbc6135e74d84d5fed.dl.dropboxusercontent.com/cd/0/inline/B7_Tfl2cTZ8M04pXotOHXCg0r-HD8p5OtMjw2dky5ia2wNVC6zY4ix6TmDFJxFwf5VSkDfSoIpTGzC9HRUqT4MO4x6WSz1_mJVyy4glmh5a3FMOnoa8aglRydQCpUisDCJW53skJ9LIxrVxeWOjkDMuPwvIOC5c-nMSXvR055Hk09A/file\r\n",
      "Resolving uc825fbd1cfbc6135e74d84d5fed.dl.dropboxusercontent.com (uc825fbd1cfbc6135e74d84d5fed.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\r\n",
      "Connecting to uc825fbd1cfbc6135e74d84d5fed.dl.dropboxusercontent.com (uc825fbd1cfbc6135e74d84d5fed.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /cd/0/inline2/B78c9BXV69N9JCGabTfrLvorsuktmcelHIy8ABChqj74Qos-5rNAa98LT8ZwECUSASFL7_A0dCfoWUuVB5FfUwuNlttfBRe8d07WdYGyiN3oR3nbG_BshNtb5uHdRRYb2InVxhyZ4u5IZNdNkPX6AOKLbOaUJ-NxMYJbiu3gs_nQel2C_PNcQlm03MySXm-GXdvWCjWmwDn4Ic3B8p-OgJ2zc0czfuhBFiLlNmW4IjmztGbHQ_fapjfe22a0Qbg46NI6s6w0Sw3GW-PGZ-ch8T8uas3PKabqsNY6GWCnEmixJy6C2uAeL92xdugXmFghlmU_37hyYsuoWWj7kdA5P523epmaKAA7DpvLpw4jiMS0hPYJCQx4W47JtdjKfkAQbopon1f8g2qhbuodXFuwn5BQQCtVhCCKPLFBhGObKcBL_A/file [following]\r\n",
      "--2023-05-13 09:23:56--  https://uc825fbd1cfbc6135e74d84d5fed.dl.dropboxusercontent.com/cd/0/inline2/B78c9BXV69N9JCGabTfrLvorsuktmcelHIy8ABChqj74Qos-5rNAa98LT8ZwECUSASFL7_A0dCfoWUuVB5FfUwuNlttfBRe8d07WdYGyiN3oR3nbG_BshNtb5uHdRRYb2InVxhyZ4u5IZNdNkPX6AOKLbOaUJ-NxMYJbiu3gs_nQel2C_PNcQlm03MySXm-GXdvWCjWmwDn4Ic3B8p-OgJ2zc0czfuhBFiLlNmW4IjmztGbHQ_fapjfe22a0Qbg46NI6s6w0Sw3GW-PGZ-ch8T8uas3PKabqsNY6GWCnEmixJy6C2uAeL92xdugXmFghlmU_37hyYsuoWWj7kdA5P523epmaKAA7DpvLpw4jiMS0hPYJCQx4W47JtdjKfkAQbopon1f8g2qhbuodXFuwn5BQQCtVhCCKPLFBhGObKcBL_A/file\r\n",
      "Reusing existing connection to uc825fbd1cfbc6135e74d84d5fed.dl.dropboxusercontent.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 489509 (478K) [application/zip]\r\n",
      "Saving to: ‘data.zip’\r\n",
      "\r\n",
      "data.zip            100%[===================>] 478.04K  --.-KB/s    in 0.02s   \r\n",
      "\r\n",
      "2023-05-13 09:23:56 (19.1 MB/s) - ‘data.zip’ saved [489509/489509]\r\n",
      "\r\n",
      "Collecting unzip\r\n",
      "  Downloading unzip-1.0.0.tar.gz (704 bytes)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: unzip\r\n",
      "  Building wheel for unzip (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for unzip: filename=unzip-1.0.0-py3-none-any.whl size=1320 sha256=13b6243c324ce0ba5c4316b1c341a64214b2d1ba7d80b20ba7bc15be1044ce87\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/dc/7a/f8af45bc239e7933509183f038ea8d46f3610aab82b35369f4\r\n",
      "Successfully built unzip\r\n",
      "Installing collected packages: unzip\r\n",
      "Successfully installed unzip-1.0.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mArchive:  ./data.zip\r\n",
      "   creating: data/\r\n",
      "   creating: data/deer/\r\n",
      " extracting: data/deer/deer13.png    \r\n",
      " extracting: data/deer/deer6.png     \r\n",
      " extracting: data/deer/deer11.png    \r\n",
      " extracting: data/deer/deer2.png     \r\n",
      " extracting: data/deer/deer10.png    \r\n",
      " extracting: data/deer/deer16.png    \r\n",
      " extracting: data/deer/deer9.png     \r\n",
      " extracting: data/deer/deer20.png    \r\n",
      " extracting: data/deer/deer15.png    \r\n",
      " extracting: data/deer/deer19.png    \r\n",
      " extracting: data/deer/deer5.png     \r\n",
      " extracting: data/deer/deer14.png    \r\n",
      " extracting: data/deer/deer4.png     \r\n",
      " extracting: data/deer/deer8.png     \r\n",
      " extracting: data/deer/deer12.png    \r\n",
      " extracting: data/deer/deer1.png     \r\n",
      " extracting: data/deer/deer7.png     \r\n",
      " extracting: data/deer/deer17.png    \r\n",
      " extracting: data/deer/deer18.png    \r\n",
      " extracting: data/deer/deer3.png     \r\n",
      "   creating: data/horse/\r\n",
      " extracting: data/horse/horse9.png   \r\n",
      " extracting: data/horse/horse1.png   \r\n",
      " extracting: data/horse/horse16.png  \r\n",
      " extracting: data/horse/horse15.png  \r\n",
      " extracting: data/horse/horse19.png  \r\n",
      " extracting: data/horse/horse14.png  \r\n",
      " extracting: data/horse/horse10.png  \r\n",
      " extracting: data/horse/horse7.png   \r\n",
      " extracting: data/horse/horse2.png   \r\n",
      " extracting: data/horse/horse6.png   \r\n",
      " extracting: data/horse/horse20.png  \r\n",
      " extracting: data/horse/horse5.png   \r\n",
      " extracting: data/horse/horse18.png  \r\n",
      " extracting: data/horse/horse12.png  \r\n",
      " extracting: data/horse/horse13.png  \r\n",
      " extracting: data/horse/horse17.png  \r\n",
      " extracting: data/horse/horse4.png   \r\n",
      " extracting: data/horse/horse11.png  \r\n",
      " extracting: data/horse/horse8.png   \r\n",
      " extracting: data/horse/horse3.png   \r\n",
      "   creating: data/ship/\r\n",
      " extracting: data/ship/ship10.png    \r\n",
      " extracting: data/ship/ship14.png    \r\n",
      " extracting: data/ship/ship9.png     \r\n",
      " extracting: data/ship/ship20.png    \r\n",
      " extracting: data/ship/ship5.png     \r\n",
      " extracting: data/ship/ship8.png     \r\n",
      " extracting: data/ship/ship19.png    \r\n",
      " extracting: data/ship/ship16.png    \r\n",
      " extracting: data/ship/ship13.png    \r\n",
      " extracting: data/ship/ship6.png     \r\n",
      " extracting: data/ship/ship17.png    \r\n",
      " extracting: data/ship/ship1.png     \r\n",
      " extracting: data/ship/ship12.png    \r\n",
      " extracting: data/ship/ship2.png     \r\n",
      " extracting: data/ship/ship3.png     \r\n",
      " extracting: data/ship/ship15.png    \r\n",
      " extracting: data/ship/ship4.png     \r\n",
      " extracting: data/ship/ship7.png     \r\n",
      " extracting: data/ship/ship11.png    \r\n",
      " extracting: data/ship/ship18.png    \r\n",
      "   creating: data/frog/\r\n",
      " extracting: data/frog/frog10.png    \r\n",
      " extracting: data/frog/frog4.png     \r\n",
      " extracting: data/frog/frog5.png     \r\n",
      " extracting: data/frog/frog20.png    \r\n",
      " extracting: data/frog/frog15.png    \r\n",
      " extracting: data/frog/frog3.png     \r\n",
      " extracting: data/frog/frog1.png     \r\n",
      " extracting: data/frog/frog14.png    \r\n",
      " extracting: data/frog/frog2.png     \r\n",
      " extracting: data/frog/frog19.png    \r\n",
      " extracting: data/frog/frog7.png     \r\n",
      " extracting: data/frog/frog11.png    \r\n",
      " extracting: data/frog/frog17.png    \r\n",
      " extracting: data/frog/frog18.png    \r\n",
      " extracting: data/frog/frog12.png    \r\n",
      " extracting: data/frog/frog16.png    \r\n",
      " extracting: data/frog/frog8.png     \r\n",
      " extracting: data/frog/frog13.png    \r\n",
      " extracting: data/frog/frog6.png     \r\n",
      " extracting: data/frog/frog9.png     \r\n",
      "   creating: data/airplane/\r\n",
      " extracting: data/airplane/airplane3.png  \r\n",
      " extracting: data/airplane/airplane4.png  \r\n",
      " extracting: data/airplane/airplane2.png  \r\n",
      " extracting: data/airplane/airplane9.png  \r\n",
      " extracting: data/airplane/airplane20.png  \r\n",
      " extracting: data/airplane/airplane18.png  \r\n",
      " extracting: data/airplane/airplane19.png  \r\n",
      " extracting: data/airplane/airplane10.png  \r\n",
      " extracting: data/airplane/airplane6.png  \r\n",
      " extracting: data/airplane/airplane13.png  \r\n",
      " extracting: data/airplane/airplane16.png  \r\n",
      " extracting: data/airplane/airplane14.png  \r\n",
      " extracting: data/airplane/airplane11.png  \r\n",
      " extracting: data/airplane/airplane1.png  \r\n",
      " extracting: data/airplane/airplane17.png  \r\n",
      " extracting: data/airplane/airplane7.png  \r\n",
      " extracting: data/airplane/airplane15.png  \r\n",
      " extracting: data/airplane/airplane5.png  \r\n",
      " extracting: data/airplane/airplane8.png  \r\n",
      " extracting: data/airplane/airplane12.png  \r\n",
      "   creating: data/bird/\r\n",
      " extracting: data/bird/bird9.png     \r\n",
      " extracting: data/bird/bird12.png    \r\n",
      " extracting: data/bird/bird10.png    \r\n",
      " extracting: data/bird/bird11.png    \r\n",
      " extracting: data/bird/bird5.png     \r\n",
      " extracting: data/bird/bird8.png     \r\n",
      " extracting: data/bird/bird4.png     \r\n",
      " extracting: data/bird/bird3.png     \r\n",
      " extracting: data/bird/bird7.png     \r\n",
      " extracting: data/bird/bird18.png    \r\n",
      " extracting: data/bird/bird14.png    \r\n",
      " extracting: data/bird/bird13.png    \r\n",
      " extracting: data/bird/bird2.png     \r\n",
      " extracting: data/bird/bird15.png    \r\n",
      " extracting: data/bird/bird17.png    \r\n",
      " extracting: data/bird/bird19.png    \r\n",
      " extracting: data/bird/bird16.png    \r\n",
      " extracting: data/bird/bird6.png     \r\n",
      " extracting: data/bird/bird20.png    \r\n",
      " extracting: data/bird/bird1.png     \r\n",
      "   creating: data/cat/\r\n",
      " extracting: data/cat/cat6.png       \r\n",
      " extracting: data/cat/cat1.png       \r\n",
      " extracting: data/cat/cat7.png       \r\n",
      " extracting: data/cat/cat19.png      \r\n",
      " extracting: data/cat/cat5.png       \r\n",
      " extracting: data/cat/cat9.png       \r\n",
      " extracting: data/cat/cat17.png      \r\n",
      " extracting: data/cat/cat2.png       \r\n",
      " extracting: data/cat/cat16.png      \r\n",
      " extracting: data/cat/cat10.png      \r\n",
      " extracting: data/cat/cat4.png       \r\n",
      " extracting: data/cat/cat18.png      \r\n",
      " extracting: data/cat/cat13.png      \r\n",
      " extracting: data/cat/cat11.png      \r\n",
      " extracting: data/cat/cat20.png      \r\n",
      " extracting: data/cat/cat15.png      \r\n",
      " extracting: data/cat/cat8.png       \r\n",
      " extracting: data/cat/cat14.png      \r\n",
      " extracting: data/cat/cat3.png       \r\n",
      " extracting: data/cat/cat12.png      \r\n",
      "   creating: data/automobile/\r\n",
      " extracting: data/automobile/automobile17.png  \r\n",
      " extracting: data/automobile/automobile11.png  \r\n",
      " extracting: data/automobile/automobile5.png  \r\n",
      " extracting: data/automobile/automobile10.png  \r\n",
      " extracting: data/automobile/automobile20.png  \r\n",
      " extracting: data/automobile/automobile2.png  \r\n",
      " extracting: data/automobile/automobile6.png  \r\n",
      " extracting: data/automobile/automobile1.png  \r\n",
      " extracting: data/automobile/automobile19.png  \r\n",
      " extracting: data/automobile/automobile7.png  \r\n",
      " extracting: data/automobile/automobile16.png  \r\n",
      " extracting: data/automobile/automobile3.png  \r\n",
      " extracting: data/automobile/automobile14.png  \r\n",
      " extracting: data/automobile/automobile12.png  \r\n",
      " extracting: data/automobile/automobile9.png  \r\n",
      " extracting: data/automobile/automobile4.png  \r\n",
      " extracting: data/automobile/automobile8.png  \r\n",
      " extracting: data/automobile/automobile13.png  \r\n",
      " extracting: data/automobile/automobile18.png  \r\n",
      " extracting: data/automobile/automobile15.png  \r\n",
      "   creating: data/dog/\r\n",
      " extracting: data/dog/dog9.png       \r\n",
      " extracting: data/dog/dog2.png       \r\n",
      " extracting: data/dog/dog15.png      \r\n",
      " extracting: data/dog/dog8.png       \r\n",
      " extracting: data/dog/dog3.png       \r\n",
      " extracting: data/dog/dog19.png      \r\n",
      " extracting: data/dog/dog12.png      \r\n",
      " extracting: data/dog/dog7.png       \r\n",
      " extracting: data/dog/dog17.png      \r\n",
      " extracting: data/dog/dog11.png      \r\n",
      " extracting: data/dog/dog16.png      \r\n",
      " extracting: data/dog/dog20.png      \r\n",
      " extracting: data/dog/dog4.png       \r\n",
      " extracting: data/dog/dog5.png       \r\n",
      " extracting: data/dog/dog14.png      \r\n",
      " extracting: data/dog/dog18.png      \r\n",
      " extracting: data/dog/dog10.png      \r\n",
      " extracting: data/dog/dog1.png       \r\n",
      " extracting: data/dog/dog13.png      \r\n",
      " extracting: data/dog/dog6.png       \r\n",
      "   creating: data/truck/\r\n",
      " extracting: data/truck/truck1.png   \r\n",
      " extracting: data/truck/truck18.png  \r\n",
      " extracting: data/truck/truck9.png   \r\n",
      " extracting: data/truck/truck4.png   \r\n",
      " extracting: data/truck/truck14.png  \r\n",
      " extracting: data/truck/truck8.png   \r\n",
      " extracting: data/truck/truck12.png  \r\n",
      " extracting: data/truck/truck15.png  \r\n",
      " extracting: data/truck/truck2.png   \r\n",
      " extracting: data/truck/truck5.png   \r\n",
      " extracting: data/truck/truck3.png   \r\n",
      " extracting: data/truck/truck10.png  \r\n",
      " extracting: data/truck/truck17.png  \r\n",
      " extracting: data/truck/truck20.png  \r\n",
      " extracting: data/truck/truck19.png  \r\n",
      " extracting: data/truck/truck13.png  \r\n",
      " extracting: data/truck/truck7.png   \r\n",
      " extracting: data/truck/truck6.png   \r\n",
      "  inflating: data/truck/truck16.png  \r\n",
      " extracting: data/truck/truck11.png  \r\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "!pip install pytorchcv\n",
    "!pip install imgaug\n",
    "\n",
    "# download\n",
    "# !gdown --id 1t2UFQXr1cr5qLMBK2oN2rY1NDypi9Nyw --output data.zip\n",
    "\n",
    "# if the above link isn't available, try this one\n",
    "!wget https://www.dropbox.com/s/lbpypqamqjpt2qz/data.zip\n",
    "!pip install unzip\n",
    "# unzip\n",
    "!unzip ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0217c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:11.258520Z",
     "iopub.status.busy": "2023-05-13T09:24:11.257542Z",
     "iopub.status.idle": "2023-05-13T09:24:12.208345Z",
     "shell.execute_reply": "2023-05-13T09:24:12.207087Z"
    },
    "id": "-a6naDouEWUZ",
    "papermill": {
     "duration": 0.967241,
     "end_time": "2023-05-13T09:24:12.210819",
     "exception": false,
     "start_time": "2023-05-13T09:24:11.243578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6b6442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:12.238765Z",
     "iopub.status.busy": "2023-05-13T09:24:12.237721Z",
     "iopub.status.idle": "2023-05-13T09:24:15.840535Z",
     "shell.execute_reply": "2023-05-13T09:24:15.839564Z"
    },
    "id": "SaEEx0Y3DMdu",
    "papermill": {
     "duration": 3.619219,
     "end_time": "2023-05-13T09:24:15.843117",
     "exception": false,
     "start_time": "2023-05-13T09:24:12.223898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 8\n",
    "\n",
    "def same_seeds(seed):\n",
    "\t  torch.manual_seed(seed)\n",
    "\t  if torch.cuda.is_available():\n",
    "\t\t    torch.cuda.manual_seed(seed)\n",
    "\t\t    torch.cuda.manual_seed_all(seed)\n",
    "\t  np.random.seed(seed)\n",
    "\t  random.seed(seed)\n",
    "\t  torch.backends.cudnn.benchmark = False\n",
    "\t  torch.backends.cudnn.deterministic = True\n",
    "same_seeds(1999) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "330ac4dc",
   "metadata": {
    "id": "Z8mIr7c0DPsh",
    "papermill": {
     "duration": 0.012331,
     "end_time": "2023-05-13T09:24:15.868604",
     "exception": false,
     "start_time": "2023-05-13T09:24:15.856273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Global Settings \n",
    "#### **[NOTE]**: Don't change the settings here, or your generated image might not meet the constraint.\n",
    "* $\\epsilon$ is fixed to be 8. But on **Data section**, we will first apply transforms on raw pixel value (0-255 scale) **by ToTensor (to 0-1 scale)** and then **Normalize (subtract mean divide std)**. $\\epsilon$ should be set to $\\frac{8}{255 * std}$ during attack.\n",
    "\n",
    "* Explaination (optional)\n",
    "    * Denote the first pixel of original image as $p$, and the first pixel of adversarial image as $a$.\n",
    "    * The $\\epsilon$ constraints tell us $\\left| p-a \\right| <= 8$.\n",
    "    * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
    "    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
    "    * After applying ToTensor() and Normalize() on $p$ and $a$, the constraint becomes $\\left| N(T(p))-N(T(a)) \\right| = \\left| \\frac{\\frac{p}{255}-mean}{std}-\\frac{\\frac{a}{255}-mean}{std} \\right| = \\frac{1}{255 * std} \\left| p-a \\right| <= \\frac{8}{255 * std}.$\n",
    "    * So, we should set $\\epsilon$ to be $\\frac{8}{255 * std}$ after ToTensor() and Normalize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19040cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:15.896941Z",
     "iopub.status.busy": "2023-05-13T09:24:15.895207Z",
     "iopub.status.idle": "2023-05-13T09:24:18.878994Z",
     "shell.execute_reply": "2023-05-13T09:24:18.878013Z"
    },
    "id": "IBdYgS2DDNL5",
    "papermill": {
     "duration": 3.000494,
     "end_time": "2023-05-13T09:24:18.881619",
     "exception": false,
     "start_time": "2023-05-13T09:24:15.881125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the mean and std are the calculated statistics from cifar_10 dataset\n",
    "cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n",
    "cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n",
    "\n",
    "# convert mean and std to 3-dimensional tensors for future operations\n",
    "mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n",
    "std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n",
    "\n",
    "epsilon = 8/255/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb7d077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:18.908815Z",
     "iopub.status.busy": "2023-05-13T09:24:18.908474Z",
     "iopub.status.idle": "2023-05-13T09:24:18.912529Z",
     "shell.execute_reply": "2023-05-13T09:24:18.911524Z"
    },
    "id": "AjNkQLoaDWba",
    "papermill": {
     "duration": 0.019816,
     "end_time": "2023-05-13T09:24:18.914539",
     "exception": false,
     "start_time": "2023-05-13T09:24:18.894723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = './data' # directory for storing benign images\n",
    "# benign images: images which do not contain adversarial perturbations\n",
    "# adversarial images: images which include adversarial perturbations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39865437",
   "metadata": {
    "id": "sNf-LoODDZXB",
    "papermill": {
     "duration": 0.012377,
     "end_time": "2023-05-13T09:24:18.939428",
     "exception": false,
     "start_time": "2023-05-13T09:24:18.927051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data\n",
    "\n",
    "Construct dataset and dataloader from root directory. Note that we store the filename of each image for future usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0465e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:18.966042Z",
     "iopub.status.busy": "2023-05-13T09:24:18.965774Z",
     "iopub.status.idle": "2023-05-13T09:24:19.217105Z",
     "shell.execute_reply": "2023-05-13T09:24:19.216103Z"
    },
    "id": "lV7rbnD5DarR",
    "outputId": "3610d736-4ce6-4054-9a9e-28cbe2cfad95",
    "papermill": {
     "duration": 0.267249,
     "end_time": "2023-05-13T09:24:19.219244",
     "exception": false,
     "start_time": "2023-05-13T09:24:18.951995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images = 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_10_mean, cifar_10_std)\n",
    "])\n",
    "\n",
    "class AdvDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.names = []\n",
    "        '''\n",
    "        data_dir\n",
    "        ├── class_dir\n",
    "        │   ├── class1.png\n",
    "        │   ├── ...\n",
    "        │   ├── class20.png\n",
    "        '''\n",
    "        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n",
    "            images = sorted(glob.glob(f'{class_dir}/*'))\n",
    "            self.images += images\n",
    "            self.labels += ([i] * len(images))\n",
    "            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transform(Image.open(self.images[idx]))\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    def __getname__(self):\n",
    "        return self.names\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "adv_set = AdvDataset(root, transform=transform)\n",
    "adv_names = adv_set.__getname__()\n",
    "adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'number of images = {adv_set.__len__()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb881919",
   "metadata": {
    "id": "C9D7eakEDflF",
    "papermill": {
     "duration": 0.012652,
     "end_time": "2023-05-13T09:24:19.244722",
     "exception": false,
     "start_time": "2023-05-13T09:24:19.232070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils -- Benign Images Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14b5639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:19.270934Z",
     "iopub.status.busy": "2023-05-13T09:24:19.270629Z",
     "iopub.status.idle": "2023-05-13T09:24:19.277197Z",
     "shell.execute_reply": "2023-05-13T09:24:19.276296Z"
    },
    "id": "byE4VH3uDduA",
    "papermill": {
     "duration": 0.022033,
     "end_time": "2023-05-13T09:24:19.279193",
     "exception": false,
     "start_time": "2023-05-13T09:24:19.257160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to evaluate the performance of model on benign images\n",
    "def epoch_benign(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yp = model(x)\n",
    "        loss = loss_fn(yp, y)\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bcda10b",
   "metadata": {
    "id": "D3L_qtufDk4j",
    "papermill": {
     "duration": 0.01261,
     "end_time": "2023-05-13T09:24:19.304098",
     "exception": false,
     "start_time": "2023-05-13T09:24:19.291488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils -- Attack Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0edc737a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:19.330433Z",
     "iopub.status.busy": "2023-05-13T09:24:19.330165Z",
     "iopub.status.idle": "2023-05-13T09:24:19.371777Z",
     "shell.execute_reply": "2023-05-13T09:24:19.370935Z"
    },
    "id": "odTOhtrtDklT",
    "papermill": {
     "duration": 0.057347,
     "end_time": "2023-05-13T09:24:19.373854",
     "exception": false,
     "start_time": "2023-05-13T09:24:19.316507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform fgsm attack\n",
    "def fgsm(model, x, y, loss_fn, epsilon=epsilon):\n",
    "    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
    "    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "    loss = loss_fn(model(x_adv), y) # calculate loss\n",
    "    loss.backward() # calculate gradient\n",
    "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
    "    grad = x_adv.grad.detach()\n",
    "    x_adv = x_adv + epsilon * grad.sign()\n",
    "    return x_adv\n",
    "\n",
    "# alpha and num_iter can be decided by yourself\n",
    "alpha = 0.8/255/std\n",
    "\n",
    "def ifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20):\n",
    "    x_adv = x.detach().clone()\n",
    "    ################ TODO: Medium baseline #######################\n",
    "    # write a loop with num_iter times\n",
    "    for i in range(num_iter):\n",
    "      # TODO: Each iteration, execute fgsm\n",
    "        x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
    "        x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "        loss = loss_fn(model(x_adv), y) # calculate loss\n",
    "        loss.backward() # calculate gradient\n",
    "        # fgsm: use gradient ascent on x_adv to maximize loss\n",
    "        x_adv = x_adv + epsilon * x_adv.grad.detach().sign()\n",
    "    return x_adv\n",
    "\n",
    "def mifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20, decay=0.1):\n",
    "    x_adv = x\n",
    "    # initialze momentum tensor\n",
    "    momentum = torch.zeros_like(x).detach().to(device)\n",
    "\n",
    "    ################ TODO: Strong baseline ####################\n",
    "    for i in range(num_iter):\n",
    "      # TODO: Refer to the algorithm of MI-FGSM\n",
    "      # Calculate the momentum and update\n",
    "        x_adv = x_adv.detach().clone()\n",
    "        x_adv.requires_grad = True\n",
    "        loss = loss_fn(model(x_adv), y) # calculate loss\n",
    "        loss.backward() # calculate gradient\n",
    "        grad = x_adv.grad.detach()\n",
    "        grad = grad / torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True)\n",
    "        grad = grad + momentum * decay\n",
    "        momentum = grad\n",
    "        x_adv = x_adv + alpha * grad.sign()\n",
    "        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon)\n",
    "    return x_adv\n",
    "\n",
    "def nifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=100, decay=1.0):\n",
    "    x_adv = x\n",
    "    # initialze momentum tensor\n",
    "    momentum = torch.zeros_like(x).detach().to(device)\n",
    "    ################ TODO: Strong baseline ####################\n",
    "    for i in range(num_iter):\n",
    "      # TODO: Refer to the algorithm of NI-FGSM\n",
    "      # Calculate the momentum and update\n",
    "        x_adv = x_adv.detach().clone()\n",
    "        x_adv.requires_grad = True\n",
    "        x_adv = x_adv + decay*alpha*momentum\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(model(x_adv), y)\n",
    "\n",
    "        # Update adversarial images\n",
    "        grad = torch.autograd.grad(loss, x_adv,\n",
    "                                   retain_graph=False, create_graph=False)[0]\n",
    "        grad = decay*momentum + grad / torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True)\n",
    "        momentum = grad\n",
    "        x_adv = x_adv + alpha * grad.sign()\n",
    "        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon)\n",
    "    return x_adv\n",
    "\n",
    "def snifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=100, decay=1.0, m=20):\n",
    "    x_adv = x\n",
    "    # initialze momentum tensor\n",
    "    momentum = torch.zeros_like(x).detach().to(device)\n",
    "    ################ TODO: Strong baseline ####################\n",
    "    for i in range(num_iter):\n",
    "      # TODO: Refer to the algorithm of NI-FGSM\n",
    "      # Calculate the momentum and update\n",
    "        x_adv = x_adv.detach().clone()\n",
    "        x_adv.requires_grad = True\n",
    "        nes_image = x_adv + decay*alpha*momentum\n",
    "        # Calculate sum the gradients over the scale copies of the input image\n",
    "        adv_grad = torch.zeros_like(x).detach().to(device)\n",
    "        for i in torch.arange(m):\n",
    "            nes_images = nes_image / torch.pow(2, i)\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(model(nes_images), y)\n",
    "            adv_grad += torch.autograd.grad(loss, x_adv,\n",
    "                                            retain_graph=False, create_graph=False)[0]\n",
    "        grad = adv_grad / m\n",
    "        \n",
    "\n",
    "        # Update adversarial images\n",
    "        \n",
    "        grad = decay*momentum + grad / torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True)\n",
    "        momentum = grad\n",
    "        x_adv = x_adv + alpha * grad.sign()\n",
    "        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon)\n",
    "    return x_adv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51cd4be4",
   "metadata": {
    "id": "0o9ww4s1DrEx",
    "papermill": {
     "duration": 0.012382,
     "end_time": "2023-05-13T09:24:19.398559",
     "exception": false,
     "start_time": "2023-05-13T09:24:19.386177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils -- Attack\n",
    "* Recall\n",
    "  * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
    "  * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
    "\n",
    "* Inverse function\n",
    "  * Inverse Normalize() can be seen as a function where $N^{-1}(x) = x*std+mean$ where $mean$ and $std$ are constants.\n",
    "  * Inverse ToTensor() can be seen as a function where $T^{-1}(x) = x*255$.\n",
    "\n",
    "* Special Noted\n",
    "  * ToTensor() will also convert the image from shape (height, width, channel) to shape (channel, height, width), so we also need to transpose the shape back to original shape.\n",
    "  * Since our dataloader samples a batch of data, what we need here is to transpose **(batch_size, channel, height, width)** back to **(batch_size, height, width, channel)** using np.transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a23369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:19.425212Z",
     "iopub.status.busy": "2023-05-13T09:24:19.424475Z",
     "iopub.status.idle": "2023-05-13T09:24:19.434664Z",
     "shell.execute_reply": "2023-05-13T09:24:19.433899Z"
    },
    "id": "rbtfv7rjDrvR",
    "papermill": {
     "duration": 0.025697,
     "end_time": "2023-05-13T09:24:19.436624",
     "exception": false,
     "start_time": "2023-05-13T09:24:19.410927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform adversarial attack and generate adversarial examples\n",
    "def gen_adv_examples(model, loader, attack, loss_fn):\n",
    "    model.eval()\n",
    "    adv_names = []\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack(model, x, y, loss_fn) # obtain adversarial examples\n",
    "        yp = model(x_adv)\n",
    "        loss = loss_fn(yp, y)\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "        # store adversarial examples\n",
    "        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n",
    "        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n",
    "        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n",
    "        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n",
    "        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n",
    "    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n",
    "\n",
    "# create directory which stores adversarial examples\n",
    "def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n",
    "    if os.path.exists(adv_dir) is not True:\n",
    "        _ = shutil.copytree(data_dir, adv_dir)\n",
    "    for example, name in zip(adv_examples, adv_names):\n",
    "        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n",
    "        im.save(os.path.join(adv_dir, name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "516c7510",
   "metadata": {
    "id": "rbLBR4bjDu7h",
    "papermill": {
     "duration": 0.012427,
     "end_time": "2023-05-13T09:24:19.461386",
     "exception": false,
     "start_time": "2023-05-13T09:24:19.448959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model / Loss Function\n",
    "\n",
    "Model list is available [here](https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/model_provider.py). Please select models which has _cifar10 suffix. Other kinds of models are prohibited, and it will be considered to be cheating if you use them. \n",
    "\n",
    "Note: Some of the models cannot be accessed/loaded. You can safely skip them since TA's model will not use those kinds of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e84d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:19.487970Z",
     "iopub.status.busy": "2023-05-13T09:24:19.487224Z",
     "iopub.status.idle": "2023-05-13T09:24:19.491720Z",
     "shell.execute_reply": "2023-05-13T09:24:19.490798Z"
    },
    "id": "xCKMshb08I1I",
    "papermill": {
     "duration": 0.019968,
     "end_time": "2023-05-13T09:24:19.493830",
     "exception": false,
     "start_time": "2023-05-13T09:24:19.473862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function is used to check whether you use models pretrained on cifar10 instead of other datasets\n",
    "def model_checker(model_name):\n",
    "  assert ('cifar10' in model_name) and ('cifar100' not in model_name), 'The model selected is not pretrained on cifar10!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecbe5b86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:19.520117Z",
     "iopub.status.busy": "2023-05-13T09:24:19.519443Z",
     "iopub.status.idle": "2023-05-13T09:24:24.561188Z",
     "shell.execute_reply": "2023-05-13T09:24:24.560310Z"
    },
    "id": "eCJU4k__DwPT",
    "outputId": "5f42b7d3-2d0a-4ba3-c29b-17242b8b62de",
    "papermill": {
     "duration": 5.057355,
     "end_time": "2023-05-13T09:24:24.563517",
     "exception": false,
     "start_time": "2023-05-13T09:24:19.506162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /root/.torch/models/resnet110_cifar10-0369-4d6ca1fc.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.163/resnet110_cifar10-0369-4d6ca1fc.pth.zip...\n",
      "benign_acc = 0.95000, benign_loss = 0.22678\n"
     ]
    }
   ],
   "source": [
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "\n",
    "model_name = 'resnet110_cifar10'\n",
    "model_checker(model_name)\n",
    "\n",
    "model = ptcv_get_model(model_name, pretrained=True).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
    "print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6ccb7d7",
   "metadata": {
    "id": "-CWEsxsUD0Mo",
    "papermill": {
     "duration": 0.012563,
     "end_time": "2023-05-13T09:24:24.588992",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.576429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67dc7f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:24.615531Z",
     "iopub.status.busy": "2023-05-13T09:24:24.615234Z",
     "iopub.status.idle": "2023-05-13T09:24:24.619348Z",
     "shell.execute_reply": "2023-05-13T09:24:24.618415Z"
    },
    "id": "xP6s-MCODyyh",
    "outputId": "388b1872-acb1-4f0e-a0be-31d76215d92e",
    "papermill": {
     "duration": 0.01982,
     "end_time": "2023-05-13T09:24:24.621349",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.601529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, fgsm, loss_fn)\n",
    "# print(f'fgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}')\n",
    "\n",
    "# create_dir(root, 'fgsm', adv_examples, adv_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f0c836e",
   "metadata": {
    "papermill": {
     "duration": 0.012799,
     "end_time": "2023-05-13T09:24:24.647011",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.634212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IFGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7a4c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:24.673262Z",
     "iopub.status.busy": "2023-05-13T09:24:24.672966Z",
     "iopub.status.idle": "2023-05-13T09:24:24.677081Z",
     "shell.execute_reply": "2023-05-13T09:24:24.676156Z"
    },
    "papermill": {
     "duration": 0.019534,
     "end_time": "2023-05-13T09:24:24.679047",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.659513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model, adv_loader, ifgsm, loss_fn)\n",
    "# print(f'ifgsm_acc = {ifgsm_acc:.5f}, ifgsm_loss = {ifgsm_loss:.5f}')\n",
    "\n",
    "# create_dir(root, 'ifgsm', adv_examples, adv_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fa11bbe",
   "metadata": {
    "papermill": {
     "duration": 0.012484,
     "end_time": "2023-05-13T09:24:24.704000",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.691516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MIFGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef398d0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:24.730841Z",
     "iopub.status.busy": "2023-05-13T09:24:24.730015Z",
     "iopub.status.idle": "2023-05-13T09:24:24.734484Z",
     "shell.execute_reply": "2023-05-13T09:24:24.733660Z"
    },
    "papermill": {
     "duration": 0.019902,
     "end_time": "2023-05-13T09:24:24.736406",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.716504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adv_examples, mifgsm_acc, mifgsm_loss = gen_adv_examples(model, adv_loader, mifgsm, loss_fn)\n",
    "# print(f'mifgsm_acc = {mifgsm_acc:.5f}, mifgsm_loss = {mifgsm_loss:.5f}')\n",
    "\n",
    "# create_dir(root, 'mifgsm', adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc9abcec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:24.763465Z",
     "iopub.status.busy": "2023-05-13T09:24:24.762536Z",
     "iopub.status.idle": "2023-05-13T09:24:24.767022Z",
     "shell.execute_reply": "2023-05-13T09:24:24.766247Z"
    },
    "id": "lx-X40vrD3S7",
    "outputId": "73f3423b-d783-4432-a6ac-b02edddf9b9e",
    "papermill": {
     "duration": 0.019879,
     "end_time": "2023-05-13T09:24:24.768858",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.748979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd fgsm\n",
    "# !tar zcvf ../fgsm.tgz *\n",
    "# %cd ..\n",
    "# %cd ifgsm\n",
    "# !tar zcvf ../ifgsm.tgz *\n",
    "# %cd ..\n",
    "# %cd mifgsm\n",
    "# !tar zcvf ../mifgsm.tgz *\n",
    "# %cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02efe05e",
   "metadata": {
    "id": "7dq5LDvJD5rB",
    "papermill": {
     "duration": 0.012656,
     "end_time": "2023-05-13T09:24:24.794074",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.781418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example of Ensemble Attack\n",
    "* Ensemble multiple models as your proxy model to increase the black-box transferability ([paper](https://arxiv.org/abs/1611.02770))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0efe77d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:24.821142Z",
     "iopub.status.busy": "2023-05-13T09:24:24.820396Z",
     "iopub.status.idle": "2023-05-13T09:24:24.827330Z",
     "shell.execute_reply": "2023-05-13T09:24:24.826392Z"
    },
    "id": "nvEX_IM8D7Rx",
    "papermill": {
     "duration": 0.022522,
     "end_time": "2023-05-13T09:24:24.829312",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.806790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################ BOSS BASELINE ######################\n",
    "\n",
    "class ensembleNet(nn.Module):\n",
    "    def __init__(self, model_names):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList([ptcv_get_model(name, pretrained=True) for name in model_names])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #################### TODO: boss baseline ###################\n",
    "        ensemble_logits = 0\n",
    "        for i, m in enumerate(self.models):\n",
    "            logits = m(x.clone())\n",
    "            ensemble_logits += logits\n",
    "        ensemble_logits = ensemble_logits / len(self.models)\n",
    "        return ensemble_logits\n",
    "        # TODO: sum up logits from multiple models  \n",
    "        # return ensemble_logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cfbca5c",
   "metadata": {
    "id": "De5J9n3WD-56",
    "papermill": {
     "duration": 0.014443,
     "end_time": "2023-05-13T09:24:24.856832",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.842389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Construct your ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a7dc6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:24.883475Z",
     "iopub.status.busy": "2023-05-13T09:24:24.883154Z",
     "iopub.status.idle": "2023-05-13T09:24:37.340407Z",
     "shell.execute_reply": "2023-05-13T09:24:37.339413Z"
    },
    "id": "9as1WHEiD_cp",
    "outputId": "e6ec6f50-da64-437b-d793-ac87d0baddfd",
    "papermill": {
     "duration": 12.472968,
     "end_time": "2023-05-13T09:24:37.342573",
     "exception": false,
     "start_time": "2023-05-13T09:24:24.869605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /root/.torch/models/preresnet110_cifar10-0386-cc08946a.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.164/preresnet110_cifar10-0386-cc08946a.pth.zip...\n",
      "Model : preresnet110_cifar10 -> benign_acc = 0.95000, benign_loss = 0.28506\n",
      "Downloading /root/.torch/models/sepreresnet110_cifar10-0454-418daea9.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.379/sepreresnet110_cifar10-0454-418daea9.pth.zip...\n",
      "Model : sepreresnet110_cifar10 -> benign_acc = 0.95000, benign_loss = 0.27381\n",
      "Downloading /root/.torch/models/diapreresnet110_cifar10-0425-56385016.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.343/diapreresnet110_cifar10-0425-56385016.pth.zip...\n",
      "Model : diapreresnet110_cifar10 -> benign_acc = 0.95000, benign_loss = 0.20748\n",
      "Downloading /root/.torch/models/densenet40_k24_bc_cifar10-0452-669c5255.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.220/densenet40_k24_bc_cifar10-0452-669c5255.pth.zip...\n",
      "Model : densenet40_k24_bc_cifar10 -> benign_acc = 0.95000, benign_loss = 0.20855\n",
      "Downloading /root/.torch/models/densenet100_k12_cifar10-0366-26089c6e.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.205/densenet100_k12_cifar10-0366-26089c6e.pth.zip...\n",
      "Model : densenet100_k12_cifar10 -> benign_acc = 0.95000, benign_loss = 0.28858\n",
      "Downloading /root/.torch/models/resnet56_cifar10-0452-628c42a2.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.163/resnet56_cifar10-0452-628c42a2.pth.zip...\n",
      "Model : resnet56_cifar10 -> benign_acc = 0.95000, benign_loss = 0.16539\n",
      "Downloading /root/.torch/models/rir_cifar10-0328-414c3e60.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.292/rir_cifar10-0328-414c3e60.pth.zip...\n",
      "Model : rir_cifar10 -> benign_acc = 0.95000, benign_loss = 0.14601\n",
      "Downloading /root/.torch/models/ror3_110_cifar10-0435-fb2a2b04.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.235/ror3_110_cifar10-0435-fb2a2b04.pth.zip...\n",
      "Model : ror3_110_cifar10 -> benign_acc = 0.95000, benign_loss = 0.28892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    'preresnet110_cifar10',\n",
    "    'sepreresnet110_cifar10',\n",
    "    'diapreresnet110_cifar10',\n",
    "    'densenet40_k24_bc_cifar10',\n",
    "    'densenet100_k12_cifar10',\n",
    "    'resnet56_cifar10',\n",
    "    'rir_cifar10',\n",
    "    'ror3_110_cifar10',\n",
    "#     'sepreresnet20_cifar10',\n",
    "#     'sepreresnet56_cifar10',\n",
    "#     'diaresnet20_cifar10',\n",
    "#     'diaresnet56_cifar10',\n",
    "]\n",
    "\n",
    "for model_num in model_names:\n",
    "    model = ptcv_get_model(model_num, pretrained=True).to(device)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "    bnunign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
    "    print(f'Model : {model_num} -> benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')\n",
    "\n",
    "# for model_name in model_names:\n",
    "#   model_checker(model_name)\n",
    "\n",
    "ensemble_model = ensembleNet(model_names).to(device)\n",
    "ensemble_model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e569dbcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:37.372751Z",
     "iopub.status.busy": "2023-05-13T09:24:37.371100Z",
     "iopub.status.idle": "2023-05-13T09:24:41.144880Z",
     "shell.execute_reply": "2023-05-13T09:24:41.142778Z"
    },
    "papermill": {
     "duration": 3.790571,
     "end_time": "2023-05-13T09:24:41.147269",
     "exception": false,
     "start_time": "2023-05-13T09:24:37.356698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign_acc = 0.95500, benign_loss = 0.12889\n"
     ]
    }
   ],
   "source": [
    "benign_acc, benign_loss = epoch_benign(ensemble_model, adv_loader, loss_fn)\n",
    "print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e48e208b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:41.176350Z",
     "iopub.status.busy": "2023-05-13T09:24:41.176040Z",
     "iopub.status.idle": "2023-05-13T09:24:41.188905Z",
     "shell.execute_reply": "2023-05-13T09:24:41.188039Z"
    },
    "papermill": {
     "duration": 0.029878,
     "end_time": "2023-05-13T09:24:41.190938",
     "exception": false,
     "start_time": "2023-05-13T09:24:41.161060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def input_diversity(x, resize_rate, diversity_prob):\n",
    "    img_size = x.shape[-1]\n",
    "    img_resize = int(img_size * resize_rate)\n",
    "\n",
    "    if resize_rate < 1:\n",
    "        img_size = img_resize\n",
    "        img_resize = x.shape[-1]\n",
    "\n",
    "    rnd = torch.randint(low=img_size, high=img_resize, size=(1,), dtype=torch.int32)\n",
    "    rescaled = F.interpolate(x, size=[rnd, rnd], mode='bilinear', align_corners=False)\n",
    "    h_rem = img_resize - rnd\n",
    "    w_rem = img_resize - rnd\n",
    "    pad_top = torch.randint(low=0, high=h_rem.item(), size=(1,), dtype=torch.int32)\n",
    "    pad_bottom = h_rem - pad_top\n",
    "    pad_left = torch.randint(low=0, high=w_rem.item(), size=(1,), dtype=torch.int32)\n",
    "    pad_right = w_rem - pad_left\n",
    "\n",
    "    padded = F.pad(rescaled, [pad_left.item(), pad_right.item(), pad_top.item(), pad_bottom.item()], value=0)\n",
    "\n",
    "    return padded if torch.rand(1) < diversity_prob else x\n",
    "\n",
    "\n",
    "def dmifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=100, decay=1.0,\n",
    "            resize_rate=0.9, diversity_prob=0.5):\n",
    "    x_adv = x\n",
    "    # initialze momentum tensor\n",
    "    momentum = torch.zeros_like(x).detach().to(device)\n",
    "\n",
    "    # write a loop of num_iter to represent the iterative times\n",
    "    for i in range(num_iter):\n",
    "        x_adv = x_adv.detach().clone()\n",
    "        x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "        loss = loss_fn(model(input_diversity(x_adv, resize_rate, diversity_prob)), y) # calculate loss\n",
    "#         loss.backward() # calculate gradient\n",
    "        # Update adversarial images\n",
    "        grad = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "#         grad = x_adv.grad.detach()\n",
    "        grad = grad / torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True)\n",
    "        grad = grad + momentum * decay\n",
    "        momentum = grad\n",
    "        x_adv = x_adv + alpha * grad.sign()\n",
    "        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon)\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2caab4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:41.219218Z",
     "iopub.status.busy": "2023-05-13T09:24:41.218945Z",
     "iopub.status.idle": "2023-05-13T09:24:41.222941Z",
     "shell.execute_reply": "2023-05-13T09:24:41.222050Z"
    },
    "papermill": {
     "duration": 0.02059,
     "end_time": "2023-05-13T09:24:41.225111",
     "exception": false,
     "start_time": "2023-05-13T09:24:41.204521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ATTACK_METHOD=snifgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51599fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:41.253527Z",
     "iopub.status.busy": "2023-05-13T09:24:41.252802Z",
     "iopub.status.idle": "2023-05-13T09:24:41.257270Z",
     "shell.execute_reply": "2023-05-13T09:24:41.256492Z"
    },
    "papermill": {
     "duration": 0.020673,
     "end_time": "2023-05-13T09:24:41.259206",
     "exception": false,
     "start_time": "2023-05-13T09:24:41.238533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(ensemble_model, adv_loader, ATTACK_METHOD, loss_fn)\n",
    "# print(f'{ATTACK_METHOD}_acc = {ifgsm_acc:.5f}, {ATTACK_METHOD}_loss = {ifgsm_loss:.5f}')\n",
    "# ATTACK_METHOD='snifgsm'\n",
    "# create_dir(root, ATTACK_METHOD, adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16a8776f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:24:41.288207Z",
     "iopub.status.busy": "2023-05-13T09:24:41.287467Z",
     "iopub.status.idle": "2023-05-13T09:34:52.303829Z",
     "shell.execute_reply": "2023-05-13T09:34:52.302354Z"
    },
    "papermill": {
     "duration": 611.033531,
     "end_time": "2023-05-13T09:34:52.306331",
     "exception": false,
     "start_time": "2023-05-13T09:24:41.272800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function dmifgsm at 0x7c6931df16c0>_acc = 0.00000, <function dmifgsm at 0x7c6931df16c0>_loss = 15.84042\n",
      "/kaggle/working/dmifgsm\n",
      "airplane/\r\n",
      "airplane/airplane3.png\r\n",
      "airplane/airplane16.png\r\n",
      "airplane/airplane11.png\r\n",
      "airplane/airplane18.png\r\n",
      "airplane/airplane17.png\r\n",
      "airplane/airplane9.png\r\n",
      "airplane/airplane15.png\r\n",
      "airplane/airplane20.png\r\n",
      "airplane/airplane13.png\r\n",
      "airplane/airplane10.png\r\n",
      "airplane/airplane5.png\r\n",
      "airplane/airplane12.png\r\n",
      "airplane/airplane7.png\r\n",
      "airplane/airplane4.png\r\n",
      "airplane/airplane19.png\r\n",
      "airplane/airplane1.png\r\n",
      "airplane/airplane14.png\r\n",
      "airplane/airplane8.png\r\n",
      "airplane/airplane2.png\r\n",
      "airplane/airplane6.png\r\n",
      "automobile/\r\n",
      "automobile/automobile2.png\r\n",
      "automobile/automobile9.png\r\n",
      "automobile/automobile10.png\r\n",
      "automobile/automobile6.png\r\n",
      "automobile/automobile3.png\r\n",
      "automobile/automobile8.png\r\n",
      "automobile/automobile4.png\r\n",
      "automobile/automobile13.png\r\n",
      "automobile/automobile7.png\r\n",
      "automobile/automobile5.png\r\n",
      "automobile/automobile17.png\r\n",
      "automobile/automobile15.png\r\n",
      "automobile/automobile1.png\r\n",
      "automobile/automobile11.png\r\n",
      "automobile/automobile12.png\r\n",
      "automobile/automobile20.png\r\n",
      "automobile/automobile16.png\r\n",
      "automobile/automobile14.png\r\n",
      "automobile/automobile19.png\r\n",
      "automobile/automobile18.png\r\n",
      "bird/\r\n",
      "bird/bird16.png\r\n",
      "bird/bird19.png\r\n",
      "bird/bird3.png\r\n",
      "bird/bird11.png\r\n",
      "bird/bird4.png\r\n",
      "bird/bird18.png\r\n",
      "bird/bird6.png\r\n",
      "bird/bird15.png\r\n",
      "bird/bird8.png\r\n",
      "bird/bird20.png\r\n",
      "bird/bird14.png\r\n",
      "bird/bird5.png\r\n",
      "bird/bird1.png\r\n",
      "bird/bird17.png\r\n",
      "bird/bird7.png\r\n",
      "bird/bird10.png\r\n",
      "bird/bird2.png\r\n",
      "bird/bird12.png\r\n",
      "bird/bird13.png\r\n",
      "bird/bird9.png\r\n",
      "cat/\r\n",
      "cat/cat18.png\r\n",
      "cat/cat16.png\r\n",
      "cat/cat4.png\r\n",
      "cat/cat19.png\r\n",
      "cat/cat10.png\r\n",
      "cat/cat14.png\r\n",
      "cat/cat11.png\r\n",
      "cat/cat1.png\r\n",
      "cat/cat15.png\r\n",
      "cat/cat12.png\r\n",
      "cat/cat13.png\r\n",
      "cat/cat20.png\r\n",
      "cat/cat8.png\r\n",
      "cat/cat7.png\r\n",
      "cat/cat5.png\r\n",
      "cat/cat6.png\r\n",
      "cat/cat9.png\r\n",
      "cat/cat2.png\r\n",
      "cat/cat17.png\r\n",
      "cat/cat3.png\r\n",
      "deer/\r\n",
      "deer/deer2.png\r\n",
      "deer/deer19.png\r\n",
      "deer/deer1.png\r\n",
      "deer/deer12.png\r\n",
      "deer/deer9.png\r\n",
      "deer/deer20.png\r\n",
      "deer/deer4.png\r\n",
      "deer/deer3.png\r\n",
      "deer/deer15.png\r\n",
      "deer/deer5.png\r\n",
      "deer/deer10.png\r\n",
      "deer/deer6.png\r\n",
      "deer/deer14.png\r\n",
      "deer/deer18.png\r\n",
      "deer/deer16.png\r\n",
      "deer/deer11.png\r\n",
      "deer/deer13.png\r\n",
      "deer/deer17.png\r\n",
      "deer/deer8.png\r\n",
      "deer/deer7.png\r\n",
      "dog/\r\n",
      "dog/dog6.png\r\n",
      "dog/dog14.png\r\n",
      "dog/dog5.png\r\n",
      "dog/dog12.png\r\n",
      "dog/dog20.png\r\n",
      "dog/dog7.png\r\n",
      "dog/dog18.png\r\n",
      "dog/dog9.png\r\n",
      "dog/dog4.png\r\n",
      "dog/dog3.png\r\n",
      "dog/dog17.png\r\n",
      "dog/dog19.png\r\n",
      "dog/dog1.png\r\n",
      "dog/dog10.png\r\n",
      "dog/dog13.png\r\n",
      "dog/dog8.png\r\n",
      "dog/dog16.png\r\n",
      "dog/dog15.png\r\n",
      "dog/dog11.png\r\n",
      "dog/dog2.png\r\n",
      "frog/\r\n",
      "frog/frog7.png\r\n",
      "frog/frog8.png\r\n",
      "frog/frog13.png\r\n",
      "frog/frog9.png\r\n",
      "frog/frog1.png\r\n",
      "frog/frog10.png\r\n",
      "frog/frog4.png\r\n",
      "frog/frog14.png\r\n",
      "frog/frog19.png\r\n",
      "frog/frog20.png\r\n",
      "frog/frog18.png\r\n",
      "frog/frog15.png\r\n",
      "frog/frog5.png\r\n",
      "frog/frog17.png\r\n",
      "frog/frog2.png\r\n",
      "frog/frog6.png\r\n",
      "frog/frog3.png\r\n",
      "frog/frog16.png\r\n",
      "frog/frog11.png\r\n",
      "frog/frog12.png\r\n",
      "horse/\r\n",
      "horse/horse3.png\r\n",
      "horse/horse6.png\r\n",
      "horse/horse4.png\r\n",
      "horse/horse14.png\r\n",
      "horse/horse11.png\r\n",
      "horse/horse1.png\r\n",
      "horse/horse20.png\r\n",
      "horse/horse9.png\r\n",
      "horse/horse16.png\r\n",
      "horse/horse15.png\r\n",
      "horse/horse7.png\r\n",
      "horse/horse17.png\r\n",
      "horse/horse8.png\r\n",
      "horse/horse10.png\r\n",
      "horse/horse12.png\r\n",
      "horse/horse18.png\r\n",
      "horse/horse19.png\r\n",
      "horse/horse2.png\r\n",
      "horse/horse5.png\r\n",
      "horse/horse13.png\r\n",
      "ship/\r\n",
      "ship/ship4.png\r\n",
      "ship/ship15.png\r\n",
      "ship/ship13.png\r\n",
      "ship/ship2.png\r\n",
      "ship/ship12.png\r\n",
      "ship/ship11.png\r\n",
      "ship/ship17.png\r\n",
      "ship/ship18.png\r\n",
      "ship/ship6.png\r\n",
      "ship/ship3.png\r\n",
      "ship/ship5.png\r\n",
      "ship/ship16.png\r\n",
      "ship/ship1.png\r\n",
      "ship/ship14.png\r\n",
      "ship/ship19.png\r\n",
      "ship/ship8.png\r\n",
      "ship/ship7.png\r\n",
      "ship/ship10.png\r\n",
      "ship/ship9.png\r\n",
      "ship/ship20.png\r\n",
      "truck/\r\n",
      "truck/truck11.png\r\n",
      "truck/truck4.png\r\n",
      "truck/truck2.png\r\n",
      "truck/truck10.png\r\n",
      "truck/truck3.png\r\n",
      "truck/truck12.png\r\n",
      "truck/truck8.png\r\n",
      "truck/truck19.png\r\n",
      "truck/truck17.png\r\n",
      "truck/truck15.png\r\n",
      "truck/truck20.png\r\n",
      "truck/truck18.png\r\n",
      "truck/truck5.png\r\n",
      "truck/truck9.png\r\n",
      "truck/truck6.png\r\n",
      "truck/truck1.png\r\n",
      "truck/truck7.png\r\n",
      "truck/truck16.png\r\n",
      "truck/truck14.png\r\n",
      "truck/truck13.png\r\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "ATTACK_METHOD=dmifgsm\n",
    "adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(ensemble_model, adv_loader, ATTACK_METHOD, loss_fn)\n",
    "print(f'{ATTACK_METHOD}_acc = {ifgsm_acc:.5f}, {ATTACK_METHOD}_loss = {ifgsm_loss:.5f}')\n",
    "ATTACK_METHOD='dmifgsm'\n",
    "create_dir(root, ATTACK_METHOD, adv_examples, adv_names)\n",
    "%cd dmifgsm\n",
    "!tar zcvf ../dmifgsm.tgz *\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54b7041e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:34:52.337798Z",
     "iopub.status.busy": "2023-05-13T09:34:52.336135Z",
     "iopub.status.idle": "2023-05-13T09:34:52.341516Z",
     "shell.execute_reply": "2023-05-13T09:34:52.340692Z"
    },
    "papermill": {
     "duration": 0.022976,
     "end_time": "2023-05-13T09:34:52.343584",
     "exception": false,
     "start_time": "2023-05-13T09:34:52.320608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd snifgsm\n",
    "# !tar zcvf ../snifgsm.tgz *\n",
    "# %cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06971ab6",
   "metadata": {
    "id": "4N6Me0GQECfZ",
    "papermill": {
     "duration": 0.013973,
     "end_time": "2023-05-13T09:34:52.371899",
     "exception": false,
     "start_time": "2023-05-13T09:34:52.357926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc1f67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:34:52.401687Z",
     "iopub.status.busy": "2023-05-13T09:34:52.400957Z",
     "iopub.status.idle": "2023-05-13T09:34:53.471188Z",
     "shell.execute_reply": "2023-05-13T09:34:53.469128Z"
    },
    "id": "RxNrXHKsEDGx",
    "outputId": "84300977-08c2-4617-8510-c66cd03eafed",
    "papermill": {
     "duration": 1.086681,
     "end_time": "2023-05-13T09:34:53.472624",
     "exception": true,
     "start_time": "2023-05-13T09:34:52.385943",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# plt.figure(figsize=(10, 20))\n",
    "# cnt = 0\n",
    "# for i, cls_name in enumerate(classes):\n",
    "#     path = f'{cls_name}/{cls_name}1.png'\n",
    "#     # benign image\n",
    "#     cnt += 1\n",
    "#     plt.subplot(len(classes), 4, cnt)\n",
    "#     im = Image.open(f'./data/{path}')\n",
    "#     logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "#     predict = logit.argmax(-1).item()\n",
    "#     prob = logit.softmax(-1)[predict].item()\n",
    "#     plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(np.array(im))\n",
    "#     # adversarial image\n",
    "#     cnt += 1\n",
    "#     plt.subplot(len(classes), 4, cnt)\n",
    "#     im = Image.open(f'./ifgsm/{path}')\n",
    "#     logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "#     predict = logit.argmax(-1).item()\n",
    "#     prob = logit.softmax(-1)[predict].item()\n",
    "#     plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(np.array(im))\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a70cafb2",
   "metadata": {
    "id": "WDc6QllJEHiC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Report Question\n",
    "* Make sure you follow below setup: the source model is \"resnet110_cifar10\", applying the vanilla fgsm attack on `dog2.png`. You can find the perturbed image in `fgsm/dog2.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860d541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T04:59:57.950443Z",
     "iopub.status.busy": "2023-05-13T04:59:57.950149Z",
     "iopub.status.idle": "2023-05-13T04:59:58.372032Z",
     "shell.execute_reply": "2023-05-13T04:59:58.370955Z",
     "shell.execute_reply.started": "2023-05-13T04:59:57.950418Z"
    },
    "id": "XhFVWA6JEH8Z",
    "outputId": "99a7ff78-5166-4ddd-f474-3b599a19a31c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # original image\n",
    "# path = f'dog/dog2.png'\n",
    "# im = Image.open(f'./data/{path}')\n",
    "# logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "# predict = logit.argmax(-1).item()\n",
    "# prob = logit.softmax(-1)[predict].item()\n",
    "# plt.title(f'benign: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
    "# plt.axis('off')\n",
    "# plt.imshow(np.array(im))\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # adversarial image \n",
    "# adv_im = Image.open(f'./nifgsm/{path}')\n",
    "# logit = model(transform(adv_im).unsqueeze(0).to(device))[0]\n",
    "# predict = logit.argmax(-1).item()\n",
    "# prob = logit.softmax(-1)[predict].item()\n",
    "# plt.title(f'adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
    "# plt.axis('off')\n",
    "# plt.imshow(np.array(adv_im))\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e204340",
   "metadata": {
    "id": "NfwhnywXEMwZ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Passive Defense - JPEG compression\n",
    "JPEG compression by imgaug package, compression rate set to 70\n",
    "\n",
    "Reference: https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.JpegCompression\n",
    "\n",
    "Note: If you haven't implemented the JPEG compression, this module will return an error. Don't worry about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c26aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T04:59:58.374364Z",
     "iopub.status.busy": "2023-05-13T04:59:58.373735Z",
     "iopub.status.idle": "2023-05-13T05:00:00.187155Z",
     "shell.execute_reply": "2023-05-13T05:00:00.185692Z",
     "shell.execute_reply.started": "2023-05-13T04:59:58.374327Z"
    },
    "id": "y2T7-L-BEKYg",
    "outputId": "366430ea-0da5-4112-d1dc-b348ebb1b010",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import imgaug.augmenters as iaa\n",
    "\n",
    "# # pre-process image\n",
    "# x = transforms.ToTensor()(adv_im)*255\n",
    "# x = x.permute(1, 2, 0).numpy()\n",
    "# x = x.astype(np.uint8)\n",
    "\n",
    "# # TODO: use \"imgaug\" package to perform JPEG compression (compression rate = 70)\n",
    "# # compressed_x =  ... x .. \n",
    "# aug = iaa.JpegCompression(compression=70)\n",
    "# compressed_x = aug.augment_image(x)\n",
    "# logit = model(transform(compressed_x).unsqueeze(0).to(device))[0]\n",
    "# predict = logit.argmax(-1).item()\n",
    "# prob = logit.softmax(-1)[predict].item()\n",
    "# plt.title(f'JPEG adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
    "# plt.axis('off')\n",
    "\n",
    "\n",
    "# plt.imshow(compressed_x)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d65043",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 696.093241,
   "end_time": "2023-05-13T09:34:55.976494",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-13T09:23:19.883253",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
